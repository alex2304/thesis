{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import gutenberg, brown, reuters, stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from operator import itemgetter\n",
    "\n",
    "from utils.nltk_utils import *\n",
    "from utils.ngrams import *\n",
    "from utils.eval import get_test_keywords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from typing import List, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.grammar_utils import tags_seq_to_symbols\n",
    "from utils.io import Cache\n",
    "from utils.ngrams import ngram2str\n",
    "\n",
    "\n",
    "observed_tags = Cache.load_observed_tags()\n",
    "terminal_rules = Cache.load_terminal_rules()\n",
    "\n",
    "\n",
    "def parse_phrases(tt_ngrams) -> Tuple[List, List[List[Tuple]]]:\n",
    "    global observed_tags, terminal_rules\n",
    "    \n",
    "    phrases = []\n",
    "    phrases_types = []\n",
    "\n",
    "    if observed_tags is None:\n",
    "        observed_tags = dict()\n",
    "\n",
    "    for tt_gram in tt_ngrams:\n",
    "        symbols = tuple(tags_seq_to_symbols([tag\n",
    "                                             for _, tag in tt_gram]))\n",
    "\n",
    "        phrase = tt_gram\n",
    "\n",
    "        # check if tags phrase has been already observed\n",
    "        tags_str = ngram2str(symbols)\n",
    "\n",
    "        if tags_str in observed_tags:\n",
    "            if observed_tags[tags_str] is not None:\n",
    "                phrases.append(phrase)\n",
    "                phrases_types.append(observed_tags[tags_str])\n",
    "\n",
    "            continue\n",
    "\n",
    "        p_types_dict = terminal_rules.get(tags_str)\n",
    "\n",
    "        if p_types_dict:\n",
    "            p_type = max(p_types_dict, key=lambda k: p_types_dict[k])\n",
    "\n",
    "            phrases.append(phrase)\n",
    "            phrases_types.append(p_type)\n",
    "\n",
    "            observed_tags[tags_str] = p_type\n",
    "\n",
    "        else:\n",
    "            observed_tags[tags_str] = None\n",
    "\n",
    "#     try:\n",
    "#         Cache.save_observed_tags(observed_tags)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         traceback.print_exc(e)\n",
    "\n",
    "    return phrases_types, phrases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = gutenberg.sents() + brown.sents() + reuters.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sents: 210608\n",
      "Words: 5503894\n",
      "Vocab: 87046\n"
     ]
    }
   ],
   "source": [
    "sents = [tuple(s) for s in sents]\n",
    "\n",
    "words = [w.lower() \n",
    "         for s in sents for w in s]\n",
    "\n",
    "vocab = sorted(list(set(words)))\n",
    "\n",
    "print('Sents:', len(sents))\n",
    "print('Words:', len(words))\n",
    "print('Vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating indexes\n",
    "\n",
    "# {sentence: sent_index}\n",
    "sents_ind = {sents[i]: i for i in range(len(sents))}\n",
    "\n",
    "# {word: word_index}\n",
    "vocab_ind = {vocab[j]: j for j in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mapping from words to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stems: 58858\n"
     ]
    }
   ],
   "source": [
    "stemmer = Stemmer()\n",
    "\n",
    "stems = [stemmer.stem(word) for word in vocab]\n",
    "\n",
    "# {word_index: stem}\n",
    "stems_map = {vocab_ind[word]: stem \n",
    "             for word, stem in zip(vocab, stems)}\n",
    "\n",
    "print('Stems:', len(set(stems)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem2word = {stem: vocab[ind]\n",
    "             for ind, stem in stems_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "model = gensim.models.Word2Vec.load('data/w2v/CBOW_300_10_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_stemmed = [[stems_map[vocab_ind[w.lower()]] for w in s] for s in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sents_stemmed, size=300, window=15, min_count=1, hs=1, negative=0)\n",
    "model.save('data/w2v/CBOW_300_10_hs_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.3553354740142822), ('daughter', 0.35418325662612915), ('esther', 0.3361766040325165), ('husband', 0.3246108889579773), ('absalom', 0.3200189769268036), ('mordecai', 0.31594496965408325), ('samaria', 0.3088769316673279), ('vashti', 0.30666205286979675), ('hebron', 0.298782080411911), ('selleth', 0.29791125655174255)]\n",
      "0.20989265750352995\n",
      "bring\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "print(model.wv.most_similar(positive=[stemmer.stem('woman'), stemmer.stem('king')], negative=[stemmer.stem('man')]))\n",
    "print(model.wv.similarity(stemmer.stem('campus'), stemmer.stem('dormitory')))\n",
    "print(model.wv.doesnt_match([stemmer.stem(w) for w in \"dormitory bring campus\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "\n",
    "with open('data/cache/stems_phrases', mode='rb') as fp:\n",
    "    stems_phrases = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = NGramsParser()\n",
    "\n",
    "sents_words_indexes = parser.parse_sents_tokens(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210608it [06:48, 515.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# {stem: Set[sentence_ind]}\n",
    "stems_phrases = defaultdict(dict)\n",
    "\n",
    "for i, (s_words, words_indexes) in tqdm(enumerate(zip(sents, sents_words_indexes), start=1)):\n",
    "    words_ttokens = nltk.pos_tag([w.lower() for w in s_words])\n",
    "    \n",
    "    tt_ngrams = [ngr\n",
    "                 for i in range(2, 5 + 1) \n",
    "                 for ngr in n_grams(words_ttokens, i, words_indexes, pad_left=False)]\n",
    "\n",
    "    types, phrases = parse_phrases(tt_ngrams)\n",
    "\n",
    "    # format and store phrases\n",
    "    for t, p in zip(types, phrases):\n",
    "        phrase_inds = tuple(vocab_ind[token] for token, _ in p)\n",
    "        \n",
    "        for word_ind in phrase_inds:\n",
    "            if vocab[word_ind] not in stop_words:\n",
    "                stem = stems_map[word_ind]\n",
    "                \n",
    "                if not stems_phrases[stem].get(t):\n",
    "                    stems_phrases[stem][t] = defaultdict(set)\n",
    "                \n",
    "                stem_phr_t = stems_phrases[stem][t]\n",
    "                \n",
    "                stem_phr_t[phrase_inds].add(sents_ind[s_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases(word, stemmed=True):\n",
    "    if stemmed:\n",
    "        stem = word\n",
    "    else:\n",
    "        stem = stemmer.stem(word)\n",
    "        \n",
    "    phrs = stems_phrases[stem]\n",
    "    \n",
    "    if not phrs:\n",
    "        return {}\n",
    "    \n",
    "    phrases_ = defaultdict(set)\n",
    "    \n",
    "    for p_type, phr_dict in phrs.items():\n",
    "        for phrase, sents in phr_dict.items():\n",
    "            phrase_ = tuple(vocab[ind] for ind in phrase)\n",
    "            \n",
    "            phrases_[p_type].add(phrase_)\n",
    "            \n",
    "    return phrases_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "with open('data/cache/stems_phrases', mode='wb') as fp:\n",
    "    pickle.dump(stems_phrases, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count number of phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for analysis\n",
    "\n",
    "phrases_count = defaultdict(dict)\n",
    "\n",
    "phrases_lengths_count = defaultdict(int)\n",
    "phrases_types_count = defaultdict(int)\n",
    "\n",
    "stems_phrases_count = defaultdict(dict)\n",
    "\n",
    "for stem, stem_phrases_dict in stems_phrases.items():\n",
    "    for phrase_type, phrases_dict in stem_phrases_dict.items():\n",
    "#         stem_phrase_type_count = sum([len(s_ids) for s_ids in phrases_dict.values()])\n",
    "        for phrase_tuple, s_ids in phrases_dict.items():\n",
    "            phrase_len = len(phrase_tuple)\n",
    "            phrase_sents_count = len(s_ids)\n",
    "            \n",
    "            if not stems_phrases_count[stem].get(phrase_len):\n",
    "                stems_phrases_count[stem][phrase_len] = defaultdict(int)\n",
    "                \n",
    "            # count number of such phrase type for given stem\n",
    "            stems_phrases_count[stem][phrase_len][phrase_type] += phrase_sents_count \n",
    "\n",
    "            # count total number of such phrase type\n",
    "            phrases_count[phrase_len][phrase_type] = phrases_count[phrase_len].get(phrase_type, 0) + phrase_sents_count\n",
    "\n",
    "            # count total number of all phrases\n",
    "            phrases_lengths_count[phrase_len] += phrase_sents_count\n",
    "            phrases_types_count[phrase_type] += phrase_sents_count\n",
    "\n",
    "all_phrases_count = sum(phrases_types_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {2: {'ADJP': 288142,\n",
       "              'ADVP': 418156,\n",
       "              'NP': 1985844,\n",
       "              'PP': 3328,\n",
       "              'VP': 66991},\n",
       "             3: {'ADJP': 44770,\n",
       "              'ADVP': 31064,\n",
       "              'NP': 1353053,\n",
       "              'PP': 7554,\n",
       "              'VP': 8215},\n",
       "             4: {'ADJP': 4179, 'ADVP': 223, 'NP': 429226},\n",
       "             5: {'ADJP': 245, 'NP': 53025}})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: defaultdict(int, {'ADJP': 42, 'ADVP': 47, 'NP': 1856, 'VP': 89}),\n",
       " 3: defaultdict(int, {'ADJP': 2, 'NP': 177, 'PP': 1, 'VP': 21}),\n",
       " 4: defaultdict(int, {'NP': 27}),\n",
       " 5: defaultdict(int, {'NP': 2})}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD = 'take'\n",
    "\n",
    "stems_phrases_count[stemmer.stem(WORD)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('NP', 2), -7.835619937610666),\n",
       " (('NP', 3), -10.185649118382983),\n",
       " (('VP', 2), -10.87316248122467),\n",
       " (('ADVP', 2), -11.511651249246752),\n",
       " (('ADJP', 2), -11.624129232673441),\n",
       " (('NP', 4), -12.065961984952482),\n",
       " (('VP', 3), -12.31727641323339),\n",
       " (('ADJP', 3), -14.668651670396866),\n",
       " (('NP', 5), -14.668651670396867),\n",
       " (('PP', 3), -15.361798850956813)]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def phrases_model(word, stemmed=True):\n",
    "    \"\"\"\n",
    "        Return sorted log probs of phrase types and length for the word \n",
    "    \"\"\"\n",
    "    if not stemmed:\n",
    "        stem = stemmer.stem(word)\n",
    "    else:\n",
    "        stem = word\n",
    "    \n",
    "    if not stems_phrases_count.get(stem):\n",
    "        return []\n",
    "    \n",
    "    stem_phrases = stems_phrases_count[stem]\n",
    "    \n",
    "    phrases_probs = []\n",
    "    \n",
    "    for p_length, p_types_count in stem_phrases.items():\n",
    "        for p_type, p_type_count in p_types_count.items():\n",
    "            prob_len = phrases_lengths_count[p_length] / all_phrases_count\n",
    "            \n",
    "            prob_len_type = phrases_count[p_length][p_type] / phrases_lengths_count[p_length]\n",
    "            \n",
    "            prob_word_len_type = p_type_count / phrases_count[p_length][p_type]\n",
    "            \n",
    "            log_prob = sum(np.log(p) for p in [prob_word_len_type, prob_len_type, prob_len])\n",
    "            \n",
    "            phrases_probs.append(((p_type, p_length), log_prob))\n",
    "    \n",
    "    phrases, scores = [], []\n",
    "    for phr, s in sorted(phrases_probs, key=itemgetter(1), reverse=True):\n",
    "        phrases.append(phr)\n",
    "        scores.append(s)\n",
    "    \n",
    "#     scores = np.exp(scores)\n",
    "#     scores /= np.max(scores)\n",
    "    \n",
    "    return list(zip(phrases, scores))\n",
    "\n",
    "phrases_model(WORD, stemmed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_PEN = {\n",
    "    2: 1.75,\n",
    "    3: 1.25,\n",
    "    4: 0.75,\n",
    "    5: 0.25\n",
    "}\n",
    "\n",
    "REVERSE = False\n",
    "SCORE_SIGN = -1\n",
    "TOP_N = 5\n",
    "\n",
    "P_TYPE_SCORE = dict(phrases_model(WORD, stemmed=False))\n",
    "\n",
    "phrases_ = get_phrases(WORD, stemmed=False)\n",
    "\n",
    "all_scored_phrases = defaultdict(dict)\n",
    "\n",
    "for p_type, phrases in phrases_.items():\n",
    "    phrases_ = list(phrases)\n",
    "    \n",
    "    scores = np.array(model.score([[stemmer.stem(w) for w in phr] \n",
    "                                   for phr in phrases_]))\n",
    "\n",
    "    for phr, sc in zip(phrases_, scores):\n",
    "        if not all_scored_phrases[p_type].get(len(phr)):\n",
    "            all_scored_phrases[p_type][len(phr)] = []\n",
    "        \n",
    "        score = SCORE_SIGN * (sc + P_TYPE_SCORE[(p_type, len(phr))]) * LENGTH_PEN[len(phr)] \n",
    "        \n",
    "        all_scored_phrases[p_type][len(phr)].append((phr, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP\n",
      "\n",
      "2\n",
      "[('taking place', 24.3107733921767),\n",
      " ('take places', 24.3107733921767),\n",
      " ('take place', 24.3107733921767),\n",
      " ('take account', 24.937590141749453),\n",
      " ('taking account', 24.937590141749453)]\n",
      "\n",
      "3\n",
      "[('its taking place', 26.98285723919577),\n",
      " ('the taking over', 27.240965616652435),\n",
      " ('taking direct action', 28.78858233685202),\n",
      " ('take effect on', 28.948198807188934),\n",
      " ('taking military action', 29.008641493269867)]\n",
      "\n",
      "4\n",
      "[('the same time taking', 21.42702209067359),\n",
      " ('a strong man taking', 25.8047634274961),\n",
      " ('take ye good heed', 26.89857112479224),\n",
      " ('the sea taking advantage', 27.499353042364262),\n",
      " ('a patrolman take over', 27.58723937582984)]\n",
      "\n",
      "5\n",
      "[('this take constant vigilance .\"', 13.749093078121678),\n",
      " (\"an employee's garden club take\", 14.565914176449315)]\n",
      "\n",
      "ADVP\n",
      "\n",
      "2\n",
      "[('taking over', 36.99610413129595),\n",
      " ('take over', 36.99610413129595),\n",
      " ('take of', 41.23225248868731),\n",
      " ('of take', 41.23225248868731),\n",
      " ('taking of', 41.23225248868731)]\n",
      "\n",
      "VP\n",
      "\n",
      "2\n",
      "[('take away', 29.890197170588603),\n",
      " ('takes away', 29.890197170588603),\n",
      " ('taking over', 35.87874878725731),\n",
      " ('take seriously', 38.14741386255943),\n",
      " ('take apart', 39.93375481447899)]\n",
      "\n",
      "3\n",
      "[('go and take', 37.72527507815673),\n",
      " ('give and take', 41.59027866397216),\n",
      " ('taking and giving', 41.59028343234374),\n",
      " ('come and take', 43.324657001832264),\n",
      " ('stay and take', 43.85522417102172)]\n",
      "\n",
      "PP\n",
      "\n",
      "3\n",
      "[('on its takings', 43.761827459264865)]\n",
      "\n",
      "ADJP\n",
      "\n",
      "2\n",
      "[('then taking', 46.55225528239214),\n",
      " ('not taking', 48.7940656042),\n",
      " ('once taking', 49.73397696970903),\n",
      " ('accidentally taking', 50.022211203565234),\n",
      " ('now taking', 51.23688853739702)]\n",
      "\n",
      "3\n",
      "[('costly and taking', 43.71989976637133), ('take ye good', 49.20127879850634)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p_type, scored_phrases in all_scored_phrases.items():\n",
    "    print('%s\\n' % p_type)\n",
    "    for n in scored_phrases:\n",
    "        nps = scored_phrases[n]\n",
    "        best_phr = sorted(nps, key=itemgetter(1), reverse=REVERSE)[:TOP_N]\n",
    "\n",
    "        best_phr = [(' '.join(p), s) for p, s in best_phr]\n",
    "\n",
    "        print(n)\n",
    "        pprint(best_phr)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'ADJP': [('costly and taking', 43.71989976637133),\n",
       "              ('then taking', 46.55225528239214),\n",
       "              ('not taking', 48.7940656042),\n",
       "              ('take ye good', 49.20127879850634),\n",
       "              ('once taking', 49.73397696970903),\n",
       "              ('accidentally taking', 50.022211203565234),\n",
       "              ('now taking', 51.23688853739702)],\n",
       "             'ADVP': [('taking over', 36.99610413129595),\n",
       "              ('take over', 36.99610413129595),\n",
       "              ('take of', 41.23225248868731),\n",
       "              ('of take', 41.23225248868731),\n",
       "              ('taking of', 41.23225248868731)],\n",
       "             'NP': [('this take constant vigilance .\"', 13.749093078121678),\n",
       "              (\"an employee's garden club take\", 14.565914176449315),\n",
       "              ('the same time taking', 21.42702209067359),\n",
       "              ('taking place', 24.3107733921767),\n",
       "              ('take places', 24.3107733921767),\n",
       "              ('take place', 24.3107733921767),\n",
       "              ('take account', 24.937590141749453),\n",
       "              ('taking account', 24.937590141749453),\n",
       "              ('a strong man taking', 25.8047634274961),\n",
       "              ('take ye good heed', 26.89857112479224),\n",
       "              ('its taking place', 26.98285723919577),\n",
       "              ('the taking over', 27.240965616652435),\n",
       "              ('the sea taking advantage', 27.499353042364262),\n",
       "              ('a patrolman take over', 27.58723937582984),\n",
       "              ('taking direct action', 28.78858233685202),\n",
       "              ('take effect on', 28.948198807188934),\n",
       "              ('taking military action', 29.008641493269867)],\n",
       "             'PP': [('on its takings', 43.761827459264865)],\n",
       "             'VP': [('take away', 29.890197170588603),\n",
       "              ('takes away', 29.890197170588603),\n",
       "              ('taking over', 35.87874878725731),\n",
       "              ('go and take', 37.72527507815673),\n",
       "              ('take seriously', 38.14741386255943),\n",
       "              ('take apart', 39.93375481447899),\n",
       "              ('give and take', 41.59027866397216),\n",
       "              ('taking and giving', 41.59028343234374),\n",
       "              ('come and take', 43.324657001832264),\n",
       "              ('stay and take', 43.85522417102172)]})"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group different length together\n",
    "\n",
    "candidate_phrases = defaultdict(list)\n",
    "\n",
    "for p_type, scored_phrases in all_scored_phrases.items():\n",
    "    for n in scored_phrases:\n",
    "        nps = scored_phrases[n]\n",
    "        best_phr = sorted(nps, key=itemgetter(1), reverse=REVERSE)[:TOP_N]\n",
    "\n",
    "        best_phr = [(' '.join(p), s) for p, s in best_phr]\n",
    "        \n",
    "        candidate_phrases[p_type].extend(best_phr)\n",
    "        \n",
    "    candidate_phrases[p_type] = sorted(candidate_phrases[p_type], key=itemgetter(1), reverse=REVERSE)\n",
    "    \n",
    "candidate_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of scoring phrases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add probabilistic CFG\n",
    "\n",
    "LENGTH_PEN = {\n",
    "    2: 1.75,\n",
    "    3: 1.25,\n",
    "    4: 0.75,\n",
    "    5: 0.5\n",
    "}\n",
    "\n",
    "REVERSE = False\n",
    "SCORE_SIGN = -1\n",
    "TOP_N = 5\n",
    "\n",
    "def get_scored_phrases(word):\n",
    "    P_TYPE_SCORE = dict(phrases_model(word, stemmed=False))\n",
    "\n",
    "    phrases_ = get_phrases(word, stemmed=False)\n",
    "\n",
    "    all_scored_phrases = defaultdict(dict)\n",
    "\n",
    "    for p_type, phrases in phrases_.items():\n",
    "        phrases_ = list(phrases)\n",
    "\n",
    "        scores = np.array(model.score([[stemmer.stem(w) for w in phr] \n",
    "                                       for phr in phrases_]))\n",
    "\n",
    "        for phr, sc in zip(phrases_, scores):\n",
    "            if not all_scored_phrases[p_type].get(len(phr)):\n",
    "                all_scored_phrases[p_type][len(phr)] = []\n",
    "\n",
    "            score = SCORE_SIGN * (sc + P_TYPE_SCORE[(p_type, len(phr))]) * LENGTH_PEN[len(phr)] \n",
    "\n",
    "            all_scored_phrases[p_type][len(phr)].append((phr, score))\n",
    "\n",
    "    # group different length together\n",
    "\n",
    "    candidate_phrases = defaultdict(list)\n",
    "\n",
    "    for p_type, scored_phrases in all_scored_phrases.items():\n",
    "        for n in scored_phrases:\n",
    "            nps = scored_phrases[n]\n",
    "            best_phr = sorted(nps, key=itemgetter(1), reverse=REVERSE)[:TOP_N]\n",
    "\n",
    "            best_phr = [(' '.join(p), s) for p, s in best_phr]\n",
    "\n",
    "            candidate_phrases[p_type].extend(best_phr)\n",
    "\n",
    "        candidate_phrases[p_type] = sorted(candidate_phrases[p_type], key=itemgetter(1), reverse=REVERSE)\n",
    "\n",
    "    return candidate_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:  874\n"
     ]
    }
   ],
   "source": [
    "kws = get_test_keywords('data/lingualeo_words.csv')\n",
    "\n",
    "print('Keywords: ', len(kws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test keywords: ['hold', 'harsh', 'nutshell', 'essential', 'implicit']\n",
      "Test keywords stems: ['hold', 'harsh', 'nutshel', 'essenti', 'implicit']\n",
      "All kws found: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 5\n",
    "np.random.seed = 0\n",
    "\n",
    "all_kws_found = False\n",
    "\n",
    "while not all_kws_found:    \n",
    "    test_kws = list(np.random.choice(list(kws), size=TEST_SIZE, replace=False))\n",
    "\n",
    "    print('Test keywords:', test_kws)\n",
    "\n",
    "    test_kws = [stemmer.stem(kw) for kw in test_kws]\n",
    "    kws_phrases = [stems_phrases.get(kw) for kw in test_kws]\n",
    "    print('Test keywords stems:', test_kws)\n",
    "\n",
    "    all_kws_found = all(kws_phrases)\n",
    "    \n",
    "    print('All kws found:', all_kws_found)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('harsh', 'nutshel'), ('essenti', 'implicit'), ('hold',)]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cluster_keywords(kws):\n",
    "    pairs = []\n",
    "\n",
    "    for i, kw in enumerate(kws):\n",
    "        cp = list(kws)\n",
    "        cp.remove(kw)\n",
    "\n",
    "        dsts = w2v.distances(kw, cp)\n",
    "#         print(kw, dsts)\n",
    "        max_ind = np.argmin(dsts)\n",
    "#         print(i, max_ind)\n",
    "        sim_kw = kws[max_ind + (1 if i <= max_ind else 0)]\n",
    "#         print(kw, sim_kw)\n",
    "\n",
    "        pair = (kw, sim_kw)\n",
    "\n",
    "        if (sim_kw, kw) in pairs:\n",
    "            pair = (sim_kw, kw)\n",
    "\n",
    "        pairs.append(pair)\n",
    "\n",
    "    final_clusters = []\n",
    "    \n",
    "    kws_ = list(kws)\n",
    "    \n",
    "    for kws_pair, cnt in Counter(pairs).items():\n",
    "        if cnt > 1:\n",
    "            final_clusters.append(kws_pair)\n",
    "            [kws_.remove(w) for w in kws_pair]\n",
    "        \n",
    "    return final_clusters + [(kw,) for kw in kws_]\n",
    "\n",
    "cluster_keywords(test_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_rules = Cache.load_terminal_rules_sents()\n",
    "\n",
    "def gen_sents_candidates(kws_ttokens, kws_phrases):\n",
    "    marks = {'COMMA': [((\",\", ','),)],\n",
    "             'COLON': [((\":\", ':'),)],\n",
    "             'SEMICOLON': [((\";\", ';'),)],\n",
    "             # 'DOT': [((\".\", '.'),)],\n",
    "             'QUESTION': [((\"?\", '?'),)],\n",
    "             'EXCLAM': [((\"!\", '!'),)],\n",
    "             'DASH': [((\"-\", '-'),)]}\n",
    "\n",
    "    sents = set()\n",
    "\n",
    "    sents_rules = load_terminal_rules_sents()\n",
    "\n",
    "    phrases = defaultdict(dict)\n",
    "\n",
    "    for tt, token_phrases in zip(kws_ttokens, kws_phrases):\n",
    "        token, tag = tt\n",
    "\n",
    "        for p_type in token_phrases:\n",
    "            phrases[p_type][token] = token_phrases[p_type]\n",
    "\n",
    "    for sents_rule in sents_rules:\n",
    "        sent_symbols = str2ngram(sents_rule)\n",
    "\n",
    "        sent = []\n",
    "        used_kws = set()\n",
    "\n",
    "        # TODO: different sent candidates with same rule\n",
    "        for p_type in sent_symbols:\n",
    "            if p_type in marks:\n",
    "                p_type_phrases = marks.get(p_type, [])\n",
    "\n",
    "            else:\n",
    "                kws_p_type_phrases = phrases.get(p_type, {})\n",
    "\n",
    "                if kws_p_type_phrases:\n",
    "                    possible_kws = set(kws_p_type_phrases.keys()).difference(used_kws)\n",
    "\n",
    "                    if not possible_kws:\n",
    "                        p_type_phrases = []\n",
    "\n",
    "                    else:\n",
    "                        kw = random.choice(list(possible_kws))\n",
    "\n",
    "                        p_type_phrases = kws_p_type_phrases[kw]\n",
    "\n",
    "                        used_kws.add(kw)\n",
    "\n",
    "                else:\n",
    "                    p_type_phrases = []\n",
    "\n",
    "            if not p_type_phrases:\n",
    "                break\n",
    "\n",
    "            sent.append(random.choice(list(p_type_phrases)))\n",
    "            # for phr_cand in list(p_type_phrases):\n",
    "            #     if phr_cand not in sent:\n",
    "            #         sent.append(phr_cand)\n",
    "            #         break\n",
    "            # else:\n",
    "            #     break\n",
    "\n",
    "        else:\n",
    "            sents.add(tuple(sent))\n",
    "\n",
    "        # sent_raw = [phrases.get(p_type, []) or marks.get(p_type, []) for p_type in sent_symbols]\n",
    "\n",
    "        # print(sent_raw)\n",
    "\n",
    "        # sents.update(self.combine_elements(*sent_raw))\n",
    "\n",
    "    return sents\n",
    "    # for p in s_patterns:\n",
    "    #     p_types = p.split(' ')\n",
    "    #\n",
    "    #     sents.update(self.combine_elements(*[phrases.get(p_type, []) for p_type in p_types]))\n",
    "    #\n",
    "    # return sents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>,\n",
      "            {'ADJP': [('hurry and harsh', 47.306611051488986),\n",
      "                      ('that harsh', 49.82088176859067),\n",
      "                      ('too harsh', 54.27049295557187),\n",
      "                      ('with harsh', 54.481192036992766),\n",
      "                      ('in harsh', 56.636364861852385),\n",
      "                      ('against harsh', 57.134663983709075)],\n",
      "             'ADVP': [('grating so harshly', 42.19585489742188),\n",
      "                      ('so harshly for', 46.04077648631959),\n",
      "                      ('so harshly', 46.86324569661306),\n",
      "                      ('harshly for attention', 50.890646691245124),\n",
      "                      ('so harshly before', 51.4001114319983),\n",
      "                      ('harshly as', 53.075660914966335),\n",
      "                      ('him harshly', 57.10561963994192),\n",
      "                      ('on harshness', 57.64470073659109),\n",
      "                      ('harshly for', 58.18717643696951)],\n",
      "             'NP': [('the harsh voice of', 25.95800840261297),\n",
      "                    ('in a harsh voice', 26.269447916773125),\n",
      "                    ('s hurry and harsh noises', 26.773807570427927),\n",
      "                    ('a harsh word against', 27.243003958490654),\n",
      "                    ('this harsh world draw thy', 27.40553097435859),\n",
      "                    ('in this harsh world', 28.183127516535087),\n",
      "                    ('with the harsh voice', 28.246912592676445),\n",
      "                    ('a harsh voice', 35.9742662387949),\n",
      "                    ('harsh voice of', 36.350311942682836),\n",
      "                    ('a harsh word', 37.4068662601572),\n",
      "                    ('the harsh voice', 37.70941705285129),\n",
      "                    ('a harsh cry', 40.57670087395724),\n",
      "                    ('and harsh', 46.1299483623485),\n",
      "                    ('a harshness', 46.80091331863207),\n",
      "                    ('a harsh', 46.80091331863207),\n",
      "                    ('his harsh', 47.92626284026903),\n",
      "                    ('the harsh', 48.15218923949999)],\n",
      "             'VP': [('murmured harshly', 61.12882084588267),\n",
      "                    ('said harshly', 61.76034397820689)]})\n",
      "defaultdict(<class 'list'>,\n",
      "            {'NP': [('a nutshell ,\"', 42.94480156413941),\n",
      "                    ('in a nutshell', 47.6789290856543),\n",
      "                    ('nutshell ,\"', 53.124130766760516),\n",
      "                    ('a nutshell', 60.46883825577419)]})\n",
      "defaultdict(<class 'list'>,\n",
      "            {'ADJP': [('essentially descriptive and empirical',\n",
      "                       36.116855688527636),\n",
      "                      ('not essential', 41.43891953015379),\n",
      "                      ('of essential', 41.58797167325071),\n",
      "                      ('essentially egocentric and isolationistic',\n",
      "                       42.29778964085918),\n",
      "                      ('design work essential', 42.59139079853423),\n",
      "                      ('an essentially military', 42.71426219746001),\n",
      "                      ('other essential', 42.96654962086729),\n",
      "                      ('not essentially different', 44.62231654926665),\n",
      "                      ('an essentially static', 44.670899103130175),\n",
      "                      ('as essential', 44.76135037922911),\n",
      "                      ('essential historical', 44.86148952031187),\n",
      "                      ('value and essential', 46.56087178989775)],\n",
      "             'ADVP': [('essentially of a', 41.006471053050085),\n",
      "                      ('essentially within the', 41.07664479343705),\n",
      "                      ('all the essential', 42.32262982456498),\n",
      "                      ('not essentially', 42.8920290587823),\n",
      "                      ('essentially not', 42.89203072771235),\n",
      "                      ('essential of', 43.04108120187922),\n",
      "                      ('essentially of', 43.04108120187922),\n",
      "                      ('as essentially', 46.214459907857616)],\n",
      "             'NP': [('the essential foreign exchange requirements',\n",
      "                     21.179029748885746),\n",
      "                    ('the essential difference between', 22.155390617155135),\n",
      "                    ('essential machinery and raw materials',\n",
      "                     22.256447122542973),\n",
      "                    ('the essential roles and missions', 24.140975282638188),\n",
      "                    ('the essential foreign exchange', 24.21127307107359),\n",
      "                    ('the essential requirements of', 25.341131088041365),\n",
      "                    ('an essential part of', 25.55545031716734),\n",
      "                    ('the essential nature of', 25.784895774625838),\n",
      "                    ('essential freight and passenger service',\n",
      "                     26.171654985396977),\n",
      "                    ('essential difference between', 30.48469753322938),\n",
      "                    ('the same essential', 32.65220613537171),\n",
      "                    ('essentially the same', 32.652208519557504),\n",
      "                    ('very essential difference', 34.593776178935556),\n",
      "                    ('essential part of', 34.68164773044923),\n",
      "                    ('this essential', 34.97111513074094),\n",
      "                    ('essentially this', 34.971116799670995),\n",
      "                    ('essential development', 41.49376942570859),\n",
      "                    ('the essentials', 41.863198775607884),\n",
      "                    ('essentially the', 41.863198775607884)],\n",
      "             'VP': [('is essentially', 40.53842061857707),\n",
      "                    ('be essentially', 40.671723068757125),\n",
      "                    ('are essentially', 42.03269714216716),\n",
      "                    ('consists essentially', 45.76652592520244),\n",
      "                    ('was essentially', 46.34967845777995)]})\n",
      "defaultdict(<class 'list'>,\n",
      "            {'ADJP': [('yet implicit', 57.10826453695188),\n",
      "                      ('explicit or implicit', 57.99209069244968),\n",
      "                      ('on implicit', 59.271414847468236),\n",
      "                      ('with implicit', 59.73918923864255),\n",
      "                      ('implicitly subsidized', 61.14367732534299),\n",
      "                      ('implicitly credulous', 63.15892037877927)],\n",
      "             'ADVP': [('implicitly if not', 44.735849015638905),\n",
      "                      ('implicitly by some', 46.29486095182665),\n",
      "                      ('implicitly if', 48.49358841855215),\n",
      "                      ('implicitly by', 51.39345952946829),\n",
      "                      ('implicit in', 61.070523471423854),\n",
      "                      ('he implicitly', 70.34090587575125)],\n",
      "             'NP': [('the gnp implicit price deflator', 27.857391402215036),\n",
      "                    ('the implicit assumption of', 29.29157077672796),\n",
      "                    ('an implicit volatility of', 29.74366819265203),\n",
      "                    ('its explicit or implicit burden', 30.7713470906916),\n",
      "                    ('an implicit admission that', 32.45246755483465),\n",
      "                    ('the international challenge implicit', 32.53190385701971),\n",
      "                    ('the implicit claim that', 32.63124143483953),\n",
      "                    ('an implicit reference', 38.91526450571944),\n",
      "                    ('an implicit volatility', 41.49807443079879),\n",
      "                    ('implicit volatility of', 41.69553508219649),\n",
      "                    ('the implicit volatility', 42.55103578028609),\n",
      "                    ('implicit assumption of', 42.58384456095626),\n",
      "                    ('imagination implicit', 47.13809102873332),\n",
      "                    ('an implicit', 47.18652838568217),\n",
      "                    ('implicit obedience', 49.05226701597697),\n",
      "                    ('implicit volatility', 49.34215349058635),\n",
      "                    ('implicit faith', 49.99042600492961)],\n",
      "             'VP': [('be implicitly', 58.55339971961175),\n",
      "                    ('trust implicitly', 67.12824884833489)]})\n",
      "defaultdict(<class 'list'>,\n",
      "            {'ADJP': [('hold on', 36.03293927661668),\n",
      "                      ('on hold', 36.03293927661668),\n",
      "                      ('holding and other', 39.714707841802706),\n",
      "                      ('firmly holding', 40.56932147495042),\n",
      "                      ('hold of', 41.02793677798997),\n",
      "                      ('now holding', 42.421471676747906)],\n",
      "             'ADVP': [('hold on', 33.331073492300604),\n",
      "                      ('on hold', 33.331073492300604),\n",
      "                      ('holding of', 38.326070993673895),\n",
      "                      ('hold of', 38.326070993673895),\n",
      "                      ('the holds', 38.812078445685),\n",
      "                      ('hold queequeg down', 40.876039972234835)],\n",
      "             'NP': [('holdings plc & lt', 16.88748832241889),\n",
      "                    ('its holding and other company', 17.625403459898372),\n",
      "                    ('holding and other company officials', 19.389024790159603),\n",
      "                    ('the bank holding company', 19.54996629254218),\n",
      "                    ('the new holding company', 19.75505013958808),\n",
      "                    ('the daily average reserve holdings', 19.957763727537532),\n",
      "                    ('the total minimum reserve holdings', 20.21950155102386),\n",
      "                    ('holding and other company', 20.559504704636296),\n",
      "                    ('a new company holding', 20.65635605351325),\n",
      "                    ('>, the industrial holding firm', 20.941545542112728),\n",
      "                    ('holding co ltd', 21.912724924727193),\n",
      "                    ('holdings ltd >', 23.645106506987325),\n",
      "                    ('holding ltd >', 23.645106506987325),\n",
      "                    ('the holding company', 23.70389814440798),\n",
      "                    ('holdings & lt', 24.806512547178976),\n",
      "                    ('holdings ltd', 26.167475325033593),\n",
      "                    ('holding ltd', 26.167475325033593),\n",
      "                    ('company holding', 27.63557551519625),\n",
      "                    ('company holdings', 27.63557551519625),\n",
      "                    ('holding company', 27.63557551519625)],\n",
      "             'PP': [('of its holdings', 35.90429675332595),\n",
      "                    ('of their holdings', 37.58182418099929),\n",
      "                    ('with his holdings', 40.07671963922073),\n",
      "                    ('from its holdings', 40.378724453368676)],\n",
      "             'VP': [('holding on', 34.99957648024193),\n",
      "                    ('hold together', 37.24934259161583),\n",
      "                    ('holds firmly', 39.53595867857567),\n",
      "                    ('holding of', 39.99457398161522),\n",
      "                    ('holding about', 40.0490495274984),\n",
      "                    ('purchase and hold', 40.99904705701142),\n",
      "                    ('buy and hold', 41.15438629803925),\n",
      "                    ('hold or force', 43.223749892094425),\n",
      "                    ('hold and enclose', 44.37371899304657),\n",
      "                    ('fusing and holding', 45.25426079449921)]})\n"
     ]
    }
   ],
   "source": [
    "for kws_tuple in cluster_keywords(test_kws):\n",
    "    for kw in kws_tuple:\n",
    "        pprint(get_scored_phrases(kw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using processed corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "t = 'grievance'\n",
    "\n",
    "s = stemmer.stem(t)\n",
    "# stems_phrases[s]\n",
    "vocab_ind['grievance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "t = 'grievance'\n",
    "\n",
    "s = stemmer.stem(t)\n",
    "\n",
    "ss = []\n",
    "for k, v in stems_phrases[s]['NP'].items():\n",
    "    ss.extend([s_id for s_id in v])\n",
    "    \n",
    "Counter(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
