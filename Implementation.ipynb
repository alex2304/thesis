{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "\n",
    "from nltk.corpus import gutenberg, brown, reuters, stopwords\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "from functools import reduce\n",
    "from operator import itemgetter\n",
    "\n",
    "from utils.nltk_utils import *\n",
    "from utils.ngrams import *\n",
    "from utils.grammar import parse_phrases\n",
    "from utils.eval import get_test_keywords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "from typing import List, Tuple\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.grammar_utils import tags_seq_to_symbols\n",
    "from utils.io import Cache\n",
    "from utils.ngrams import ngram2str\n",
    "\n",
    "\n",
    "observed_tags = Cache.load_observed_tags()\n",
    "terminal_rules = Cache.load_terminal_rules()\n",
    "\n",
    "\n",
    "def parse_phrases(tt_ngrams) -> Tuple[List, List[List[Tuple]]]:\n",
    "    global observed_tags, terminal_rules\n",
    "    \n",
    "    phrases = []\n",
    "    phrases_types = []\n",
    "\n",
    "    if observed_tags is None:\n",
    "        observed_tags = dict()\n",
    "\n",
    "    for tt_gram in tt_ngrams:\n",
    "        symbols = tuple(tags_seq_to_symbols([tag\n",
    "                                             for _, tag in tt_gram]))\n",
    "\n",
    "        phrase = tt_gram\n",
    "\n",
    "        # check if tags phrase has been already observed\n",
    "        tags_str = ngram2str(symbols)\n",
    "\n",
    "        if tags_str in observed_tags:\n",
    "            if observed_tags[tags_str] is not None:\n",
    "                phrases.append(phrase)\n",
    "                phrases_types.append(observed_tags[tags_str])\n",
    "\n",
    "            continue\n",
    "\n",
    "        p_types_dict = terminal_rules.get(tags_str)\n",
    "\n",
    "        if p_types_dict:\n",
    "            p_type = max(p_types_dict, key=lambda k: p_types_dict[k])\n",
    "\n",
    "            phrases.append(phrase)\n",
    "            phrases_types.append(p_type)\n",
    "\n",
    "            observed_tags[tags_str] = p_type\n",
    "\n",
    "        else:\n",
    "            observed_tags[tags_str] = None\n",
    "\n",
    "#     try:\n",
    "#         Cache.save_observed_tags(observed_tags)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         traceback.print_exc(e)\n",
    "\n",
    "    return phrases_types, phrases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = gutenberg.sents() + brown.sents() + reuters.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sents: 210608\n",
      "Words: 5503894\n",
      "Vocab: 87046\n"
     ]
    }
   ],
   "source": [
    "sents = [tuple(s) for s in sents]\n",
    "\n",
    "words = [w.lower() \n",
    "         for s in sents for w in s]\n",
    "\n",
    "vocab = sorted(list(set(words)))\n",
    "\n",
    "print('Sents:', len(sents))\n",
    "print('Words:', len(words))\n",
    "print('Vocab:', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating indexes\n",
    "\n",
    "# {sentence: sent_index}\n",
    "sents_ind = {sents[i]: i for i in range(len(sents))}\n",
    "\n",
    "# {word: word_index}\n",
    "vocab_ind = {vocab[j]: j for j in range(len(vocab))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mapping from words to sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stems: 58858\n"
     ]
    }
   ],
   "source": [
    "stemmer = Stemmer()\n",
    "\n",
    "stems = [stemmer.stem(word) for word in vocab]\n",
    "\n",
    "# {word_index: stem}\n",
    "stems_map = {vocab_ind[word]: stem \n",
    "             for word, stem in zip(vocab, stems)}\n",
    "\n",
    "print('Stems:', len(set(stems)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem2word = {stem: vocab[ind]\n",
    "             for ind, stem in stems_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "\n",
    "with open('data/cache/stems_phrases', mode='rb') as fp:\n",
    "    stems_phrases = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = NGramsParser()\n",
    "\n",
    "sents_words_indexes = parser.parse_sents_tokens(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "210608it [07:18, 480.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# {stem: Set[sentence_ind]}\n",
    "stems_phrases = defaultdict(dict)\n",
    "\n",
    "for i, (s_words, words_indexes) in tqdm(enumerate(zip(sents, sents_words_indexes), start=1)):\n",
    "    words_ttokens = nltk.pos_tag([w.lower() for w in s_words])\n",
    "    \n",
    "    tt_ngrams = [ngr\n",
    "                 for i in range(1, 5 + 1) \n",
    "                 for ngr in n_grams(words_ttokens, i, words_indexes, pad_left=False)]\n",
    "\n",
    "    types, phrases = parse_phrases(tt_ngrams)\n",
    "\n",
    "    # format and store phrases\n",
    "    for t, p in zip(types, phrases):\n",
    "        phrase_inds = tuple(vocab_ind[token] for token, _ in p)\n",
    "        \n",
    "        for word_ind in phrase_inds:\n",
    "            if vocab[word_ind] not in stop_words:\n",
    "                stem = stems_map[word_ind]\n",
    "                \n",
    "                if not stems_phrases[stem].get(t):\n",
    "                    stems_phrases[stem][t] = defaultdict(set)\n",
    "                \n",
    "                stem_phr_t = stems_phrases[stem][t]\n",
    "                \n",
    "                stem_phr_t[phrase_inds].add(sents_ind[s_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phrases(word, stemmed=True):\n",
    "    if stemmed:\n",
    "        stem = word\n",
    "    else:\n",
    "        stem = stemmer.stem(word)\n",
    "        \n",
    "    phrs = stems_phrases[stem]\n",
    "    \n",
    "    if not phrs:\n",
    "        return {}\n",
    "    \n",
    "    phrases_ = defaultdict(set)\n",
    "    \n",
    "    for p_type, phr_dict in phrs.items():\n",
    "        for phrase, sents in phr_dict.items():\n",
    "            phrase_ = tuple(vocab[ind] for ind in phrase)\n",
    "            \n",
    "            phrases_[p_type].add(phrase_)\n",
    "            \n",
    "    return phrases_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "with open('data/cache/stems_phrases', mode='wb') as fp:\n",
    "    pickle.dump(stems_phrases, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "model = gensim.models.Word2Vec.load('data/w2v/CBOW_300_10_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_stemmed = [[stems_map[vocab_ind[w.lower()]] for w in s] for s in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(sentences=sents_stemmed, size=300, window=15, min_count=1, hs=1, negative=0)\n",
    "model.save('data/w2v/CBOW_300_10_hs_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.3553354740142822), ('daughter', 0.35418325662612915), ('esther', 0.3361766040325165), ('husband', 0.3246108889579773), ('absalom', 0.3200189769268036), ('mordecai', 0.31594496965408325), ('samaria', 0.3088769316673279), ('vashti', 0.30666205286979675), ('hebron', 0.298782080411911), ('selleth', 0.29791125655174255)]\n",
      "0.20989265750352995\n",
      "bring\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "\n",
    "print(model.wv.most_similar(positive=[stemmer.stem('woman'), stemmer.stem('king')], negative=[stemmer.stem('man')]))\n",
    "print(model.wv.similarity(stemmer.stem('campus'), stemmer.stem('dormitory')))\n",
    "print(model.wv.doesnt_match([stemmer.stem(w) for w in \"dormitory bring campus\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:  874\n"
     ]
    }
   ],
   "source": [
    "kws = get_test_keywords('data/lingualeo_words.csv')\n",
    "\n",
    "print('Keywords: ', len(kws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test keywords: ['advice', 'drab', 'shame', 'proclivity', 'admissible']\n",
      "Test keywords stems: ['advic', 'drab', 'shame', 'procliv', 'admiss']\n",
      "All kws found: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TEST_SIZE = 5\n",
    "np.random.seed = 0\n",
    "\n",
    "all_kws_found = False\n",
    "\n",
    "while not all_kws_found:    \n",
    "    test_kws = list(np.random.choice(list(kws), size=TEST_SIZE, replace=False))\n",
    "\n",
    "    print('Test keywords:', test_kws)\n",
    "\n",
    "    test_kws = [stemmer.stem(kw) for kw in test_kws]\n",
    "    kws_phrases = [stems_phrases.get(kw) for kw in test_kws]\n",
    "    print('Test keywords stems:', test_kws)\n",
    "\n",
    "    all_kws_found = all(kws_phrases)\n",
    "    \n",
    "    print('All kws found:', all_kws_found)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advic [1.0484983  0.5876609  0.67798024 0.6448846 ]\n",
      "0 1\n",
      "advic shame\n",
      "drab [1.0484983  0.85772705 0.5455078  0.85652786]\n",
      "1 2\n",
      "drab procliv\n",
      "shame [0.5876609  0.85772705 0.9682493  0.80564225]\n",
      "2 0\n",
      "shame advic\n",
      "procliv [0.67798024 0.5455078  0.9682493  0.66142946]\n",
      "3 1\n",
      "procliv drab\n",
      "admiss [0.6448846  0.85652786 0.8056423  0.66142946]\n",
      "4 0\n",
      "admiss advic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({('admiss', 'advic'): 1,\n",
       "         ('advic', 'shame'): 2,\n",
       "         ('drab', 'procliv'): 2})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_pairs_counter(test_kws):\n",
    "    pairs = []\n",
    "\n",
    "    for i, kw in enumerate(test_kws):\n",
    "        cp = list(test_kws)\n",
    "        cp.remove(kw)\n",
    "\n",
    "        dsts = w2v.distances(kw, cp)\n",
    "        print(kw, dsts)\n",
    "        max_ind = np.argmin(dsts)\n",
    "        print(i, max_ind)\n",
    "        sim_kw = test_kws[max_ind + (1 if i <= max_ind else 0)]\n",
    "        print(kw, sim_kw)\n",
    "\n",
    "        pair = (kw, sim_kw)\n",
    "\n",
    "        if (sim_kw, kw) in pairs:\n",
    "            pair = (sim_kw, kw)\n",
    "\n",
    "        pairs.append(pair)\n",
    "\n",
    "    return Counter(pairs)\n",
    "\n",
    "get_pairs_counter(test_kws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {1: [(('advice',), -10.578289)],\n",
       "             2: [(('advice', 'the'), -16.795265),\n",
       "              (('our', 'advice'), -15.781087),\n",
       "              (('my', 'advice'), -10.6507635),\n",
       "              (('advice', '.\"'), -18.548414),\n",
       "              (('earnest', 'advice'), -22.291565),\n",
       "              (('outside', 'advice'), -23.856993),\n",
       "              (('further', 'advice'), -17.321638),\n",
       "              (('thy', 'advice'), -18.719074),\n",
       "              (('reiterating', 'advice'), -19.005373),\n",
       "              (('personalized', 'advice'), -24.278847),\n",
       "              (('considerate', 'advice'), -20.146019),\n",
       "              (('which', 'advice'), -20.232025),\n",
       "              (('advice', ',\"'), -19.815565),\n",
       "              ((\"hetman's\", 'advice'), -22.865692),\n",
       "              (('and', 'advice'), -13.891079),\n",
       "              (('advice', 'i'), -17.141329),\n",
       "              (('aid', 'advice'), -21.918184),\n",
       "              (('wholesome', 'advice'), -21.598211),\n",
       "              (('this', 'advice'), -14.548938),\n",
       "              (('advice', '--\"'), -22.253298),\n",
       "              (('him', 'advice'), -13.957809),\n",
       "              (('sensible', 'advice'), -25.640583),\n",
       "              (('other', 'advice'), -19.4825),\n",
       "              (('her', 'advice'), -16.989557),\n",
       "              (('medical', 'advice'), -30.800238),\n",
       "              (('wanted', 'advice'), -13.039914),\n",
       "              (('such', 'advice'), -15.684699),\n",
       "              ((\"dentist's\", 'advice'), -26.950455),\n",
       "              (('helpful', 'advice'), -17.52786),\n",
       "              (('legal', 'advice'), -15.975869),\n",
       "              (('or', 'advice'), -21.720125),\n",
       "              (('pending', 'advice'), -24.8985),\n",
       "              (('took', 'advice'), -24.032701),\n",
       "              (('excellent', 'advice'), -24.904179),\n",
       "              (('take', 'advice'), -14.068565),\n",
       "              (('sense', 'advice'), -21.580338),\n",
       "              (('advice', 'ever'), -19.252995),\n",
       "              (('you', 'advice'), -15.19717),\n",
       "              (('no', 'advice'), -16.06314),\n",
       "              (('the', 'advice'), -16.795265),\n",
       "              (('your', 'advice'), -16.543774),\n",
       "              (('earthy', 'advice'), -28.249744),\n",
       "              (('soundest', 'advice'), -25.161888),\n",
       "              (('his', 'advice'), -16.110434),\n",
       "              (('free', 'advice'), -30.095888),\n",
       "              (('technical', 'advice'), -16.884153),\n",
       "              (('good', 'advice'), -17.706268),\n",
       "              (('all', 'advice'), -17.159756),\n",
       "              (('whose', 'advice'), -22.420021),\n",
       "              (('conscientious', 'advice'), -23.294598),\n",
       "              (('homely', 'advice'), -26.244074),\n",
       "              (('give', 'advice'), -11.619597),\n",
       "              (('savvy', 'advice'), -28.858244),\n",
       "              (('s', 'advice'), -18.181467),\n",
       "              (('own', 'advice'), -27.754745),\n",
       "              (('their', 'advice'), -14.301361),\n",
       "              (('what', 'advice'), -22.217775),\n",
       "              ((\"anyone's\", 'advice'), -19.779125),\n",
       "              (('best', 'advice'), -20.246466),\n",
       "              (('any', 'advice'), -23.242525),\n",
       "              (('policy', 'advice'), -17.78145),\n",
       "              (('written', 'advice'), -24.741808),\n",
       "              ((\"mathias'\", 'advice'), -24.32984)],\n",
       "             3: [(('for', 'thy', 'advice'), -23.686205),\n",
       "              (('support', 'and', 'advice'), -19.851334),\n",
       "              (('legal', 'advice', 'in'), -22.423513),\n",
       "              (('advice', 'or', 'threats'), -33.67209),\n",
       "              (('heart', 'the', 'advice'), -25.40514),\n",
       "              (('such', 'advice', 'as'), -12.637161),\n",
       "              (('the', 'advice', 'they'), -24.485636),\n",
       "              (('his', 'own', 'advice'), -18.808615),\n",
       "              (('legal', 'advice', 'on'), -20.54418),\n",
       "              ((\"hetman's\", 'advice', 'of'), -25.317257),\n",
       "              (('my', 'best', 'advice'), -24.01864),\n",
       "              (('medical', 'advice', 'on'), -29.416555),\n",
       "              (('taking', 'legal', 'advice'), -20.050909),\n",
       "              (('fears', 'and', 'advice'), -22.138815),\n",
       "              (('personalized', 'advice', 'on'), -25.597824),\n",
       "              (('thy', 'advice', 'in'), -22.468962),\n",
       "              (('for', 'policy', 'advice'), -23.39638),\n",
       "              (('the', 'soundest', 'advice'), -29.025713),\n",
       "              (('kindness', 'and', 'advice'), -23.728971),\n",
       "              (('bid', 'pending', 'advice'), -28.884678),\n",
       "              (('for', 'medical', 'advice'), -26.077467),\n",
       "              (('of', 'the', 'advice'), -18.26074),\n",
       "              (('her', 'earthy', 'advice'), -28.366766),\n",
       "              (('my', 'advice', '--\"'), -25.725927),\n",
       "              (('followed', 'thy', 'advice'), -23.045391),\n",
       "              (('common', 'sense', 'advice'), -30.856598),\n",
       "              (('outside', 'legal', 'advice'), -26.797123),\n",
       "              (('your', 'advice', 'on'), -19.768656),\n",
       "              (('advice', 'and', 'counsel'), -22.213139),\n",
       "              (('of', 'homely', 'advice'), -25.413702),\n",
       "              (('their', 'advice', '.\"'), -18.64547),\n",
       "              (('their', \"dentist's\", 'advice'), -27.393084),\n",
       "              (('the', 'advice', 'given'), -20.168623),\n",
       "              (('guidance', 'and', 'advice'), -24.528597),\n",
       "              (('some', 'other', 'advice'), -20.063591),\n",
       "              (('any', 'advice', 'of'), -21.68004),\n",
       "              (('in', 'further', 'advice'), -23.276869),\n",
       "              (('the', 'advice', 'of'), -18.26074),\n",
       "              (('after', 'the', 'advice'), -24.618),\n",
       "              (('free', 'advice', 'of'), -26.412619),\n",
       "              (('advice', 'to', 'semiconductor'), -30.559248),\n",
       "              (('with', 'good', 'advice'), -21.134663),\n",
       "              (('under', 'the', 'advice'), -20.346807),\n",
       "              (('my', 'advice', 'as'), -20.453085),\n",
       "              (('mrs.', \"mathias'\", 'advice'), -24.887596),\n",
       "              (('more', 'savvy', 'advice'), -42.70247),\n",
       "              (('undiluted', 'conscientious', 'advice'), -36.6922),\n",
       "              (('very', 'good', 'advice'), -21.780853),\n",
       "              (('here', 'your', 'advice'), -24.305058),\n",
       "              (('no', 'advice', 'under'), -25.523554),\n",
       "              (('wanted', 'outside', 'advice'), -27.588316),\n",
       "              (('opinions', 'and', 'advice'), -23.401173),\n",
       "              (('exactly', 'the', 'advice'), -26.961056),\n",
       "              (('the', 'free', 'advice'), -26.378153),\n",
       "              (('the', \"hetman's\", 'advice'), -26.280964),\n",
       "              (('s', 'considerate', 'advice'), -24.13342),\n",
       "              (('much', 'wholesome', 'advice'), -30.252115),\n",
       "              (('my', 'advice', ',\"'), -26.614004),\n",
       "              (('their', 'advice', 'for'), -18.533184),\n",
       "              (('him', 'good', 'advice'), -24.105585),\n",
       "              (('with', 'the', 'advice'), -19.95405),\n",
       "              (('the', 'earnest', 'advice'), -27.115028),\n",
       "              (('advice', 'or', 'assistance'), -28.154137),\n",
       "              (('comfort', 'or', 'advice'), -29.423376),\n",
       "              (('as', 'the', 'advice'), -21.39538)],\n",
       "             4: [(('hammarskjold', 'wanted', 'outside', 'advice'), -35.5414),\n",
       "              (('good', 'common', 'sense', 'advice'), -31.940449),\n",
       "              (('the', \"hetman's\", 'advice', 'of'), -29.096107),\n",
       "              (('for', 'some', 'other', 'advice'), -23.814346),\n",
       "              (('clear', 'and', 'sensible', 'advice'), -31.617895),\n",
       "              (('the', 'soundest', 'advice', 'ever'), -37.216938),\n",
       "              (('thy', 'advice', 'or', 'threats'), -37.49759),\n",
       "              (('the', 'free', 'advice', 'of'), -28.051847),\n",
       "              (('your', 'advice', 'and', 'counsel'), -25.596104),\n",
       "              (('close-in', 'support', 'and', 'advice'), -36.173508),\n",
       "              (('her', 'kindness', 'and', 'advice'), -27.856691),\n",
       "              (('s', 'fears', 'and', 'advice'), -30.50019)],\n",
       "             5: [(('the', 'close-in', 'support', 'and', 'advice'),\n",
       "               -41.098873)]})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_ = get_phrases('advice', stemmed=False)\n",
    "\n",
    "scored_nps = defaultdict(list)\n",
    "\n",
    "for p_type, phrases in phrases_.items():\n",
    "    if p_type != 'NP':\n",
    "        continue\n",
    "    \n",
    "    for phr in list(phrases):\n",
    "        sc = model.score([[stemmer.stem(w) for w in phr]])\n",
    "        \n",
    "        scored_nps[len(phr)].append((phr, sc[0]))\n",
    "        \n",
    "scored_nps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[('shames', -9.87307), ('shamed', -9.87307), ('shame', -9.87307)]\n",
      "\n",
      "2\n",
      "[('my shame', -13.203539),\n",
      " ('my shames', -13.203539),\n",
      " ('their shame', -13.206809)]\n",
      "\n",
      "3\n",
      "[('their own shame', -15.359652),\n",
      " ('their shame with', -16.79156),\n",
      " ('thine own shame', -18.197964)]\n",
      "\n",
      "4\n",
      "[('bear thine own shame', -25.143646),\n",
      " ('such a shameful sight', -27.247032),\n",
      " ('the shamed and angry', -27.456865)]\n",
      "\n",
      "5\n",
      "[('the measureless shame and humiliation', -41.16781),\n",
      " ('an ignominy and shame beneath', -41.686546),\n",
      " ('a prudent man covereth shame', -43.493618)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5 + 1):\n",
    "    nps = scored_nps[i]\n",
    "    best_nps = sorted(nps, key=itemgetter(1), reverse=True)[:3]\n",
    "    \n",
    "    best_nps = [(' '.join(p), s) for p, s in best_nps]\n",
    "    \n",
    "    print(i)\n",
    "    pprint(best_nps)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[('advice', -10.578289)]\n",
      "\n",
      "2\n",
      "[('my advice', -10.6507635),\n",
      " ('give advice', -11.619597),\n",
      " ('wanted advice', -13.039914),\n",
      " ('and advice', -13.891079),\n",
      " ('him advice', -13.957809)]\n",
      "\n",
      "3\n",
      "[('such advice as', -12.637161),\n",
      " ('of the advice', -18.26074),\n",
      " ('the advice of', -18.26074),\n",
      " ('their advice for', -18.533184),\n",
      " ('their advice .\"', -18.64547)]\n",
      "\n",
      "4\n",
      "[('for some other advice', -23.814346),\n",
      " ('your advice and counsel', -25.596104),\n",
      " ('her kindness and advice', -27.856691),\n",
      " ('the free advice of', -28.051847),\n",
      " (\"the hetman's advice of\", -29.096107)]\n",
      "\n",
      "5\n",
      "[('the close-in support and advice', -41.098873)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5 + 1):\n",
    "    nps = scored_nps[i]\n",
    "    best_nps = sorted(nps, key=itemgetter(1), reverse=True)[:5]\n",
    "    \n",
    "    best_nps = [(' '.join(p), s) for p, s in best_nps]\n",
    "    \n",
    "    print(i)\n",
    "    pprint(best_nps)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using processed corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "t = 'grievance'\n",
    "\n",
    "s = stemmer.stem(t)\n",
    "# stems_phrases[s]\n",
    "vocab_ind['grievance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "t = 'grievance'\n",
    "\n",
    "s = stemmer.stem(t)\n",
    "\n",
    "ss = []\n",
    "for k, v in stems_phrases[s]['NP'].items():\n",
    "    ss.extend([s_id for s_id in v])\n",
    "    \n",
    "Counter(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
